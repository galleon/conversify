[agent]
env_file = ".env.local"
instructions_file = "conversify/prompts/llm.txt"
greeting = "Hey! How are you doing today?"
goodbye = "Goodbye! Have a great day!"
default_participant_identity = "identity-qfXx"
use_eou = false                                # livekit turn detection
use_background_noise_removal = true            # uses Krisp BVC noise cancellation
use_background_audio = false                   # plays office background audio while agent speaks
allow_interruptions = true                     # reset tts on user interruption

[stt.whisper]
language = "en"
model = "deepdml/faster-whisper-large-v3-turbo-ct2"
device = "cpu"
compute_type = "auto"                          # "int8_float16"
model_cache_directory = "conversify/data/models_cache"
warmup_audio = "conversify/data/warmup_audio.wav"

[llm]
base_url = "http://ollama:11434/v1"
api_key = "ollama"
model = "qwen2.5vl"
temperature = 0.4
parallel_tool_calls = false
tool_choice = "auto"

[tts.kokoro]
base_url = "http://kokoro:8880/v1"
api_key = "NULL"
model = "tts-1"
voice = "af_heart"
speed = 1.0

[vad]
min_speech_duration = 0.20      # Minimum duration (s) for speech detection
min_silence_duration = 0.40     # Minimum silence duration (s) to detect end of speech
prefix_padding_duration = 0.5   # Padding duration (s) before detected speech
max_buffered_speech = 60.0      # Maximum buffered speech duration
activation_threshold = 0.5      # Threshold for VAD
force_cpu = false               # Force VAD to run on CPU
sample_rate = 16000

[vision]
use = true
video_frame_interval = 0.2

[memory]
use = false
dir = "conversify/data/memory_store"
load_last_n = 6

[embedding]
vllm_model_name = "mxbai-embed-large"

[worker]
job_memory_warn_mb = 1900
load_threshold = 1.0
job_memory_limit_mb = 10000

[logging]
level = "DEBUG"
file = "logs/app.log"
