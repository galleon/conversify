agent:
  env_file: ".env.local"
  instructions_file: conversify/prompts/llm.txt
  greeting: "Hey! How are you doing today?"
  goodbye: "Goodbye! Have a great day!"
  default_participant_identity: "identity-qfXx"
  use_eou: false                                      # livekit turn detection
  use_background_noise_removal: true                  # uses Krisp BVC noise cancellation
  use_background_audio: false                         # plays office background audio and keyboard typing sound while the agent speaks
  allow_interruptions: True                           # reset tts on user iterruption

stt:
  whisper:
    language: "en"
    model: "deepdml/faster-whisper-large-v3-turbo-ct2"
    device: "cpu"
    compute_type: "int8"
    model_cache_directory: "conversify/data/models_cache"
    warmup_audio: "conversify/data/warmup_audio.wav"

llm:
  base_url: "http://llm:30000/v1"
  api_key: "NULL"
  model: "Qwen/Qwen2.5-VL-7B-Instruct-AWQ"
  temperature: 0.4
  parallel_tool_calls: false
  tool_choice: "auto"

tts:
  kokoro:
    base_url: "http://kokoro:8880/v1"
    api_key: "NULL"
    model: "tts-1"
    voice: "af_heart"
    speed: 1.0

vad:
  min_speech_duration: 0.20             # Minimum duration (seconds) for speech detection
  min_silence_duration: 0.40            # Minimum silence duration (seconds) to detect end of speech
  prefix_padding_duration: 0.5          # Padding duration (seconds) before detected speech
  max_buffered_speech: 60.0             # Maximum duration (seconds) of buffered speech
  activation_threshold: 0.5             # Threshold for voice activation detection
  force_cpu: false                      # Force VAD to run on CPU instead of GPU
  sample_rate: 16000

vision:
  use: true
  video_frame_interval: 0.2

memory:
  use: false
  dir: "conversify/data/memory_store"
  load_last_n: 6

embedding:
  vllm_model_name: "mixedbread-ai/mxbai-embed-large-v1"

worker:
  job_memory_warn_mb: 1900
  load_threshold: 1.0
  job_memory_limit_mb: 10000

logging:
  level: "DEBUG"
  file: "logs/app.log"
